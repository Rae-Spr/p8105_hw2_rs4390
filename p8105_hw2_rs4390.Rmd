---
title: "p8105_hw2_rs4390"
author: "Rae Spriggs"
date: "2022-09-29"
output: github_document
---

```{r, message = FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
```

# Problem 1

```{r, message = FALSE}
transit_df = read_csv('data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv') %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>%
  mutate_at(c('route8', 'route9', 'route10', 'route11'), as.character) 

```

## Dataset description 

The transit_df dataset contains `r nrow(transit_df)` observations of individual New York City transit subway entrances and/or exits. There are `r ncol(transit_df)` total variables that detail the name of the transit lines, transit station names, station latitudes and longitudes, route numbers served, whether or not the exit also doubles as an entrance, vending access, entrance type, and ADA compliance. To clean the data, I used the `clean_names` function from the `janitor` package to make all variable names lowercase and snake_case. Then, I selected for the variables of interest listed above. I mutated the variable types for routes 8-11, so they would also be character variables. The resulting dataset has dimensions described above, which are 1868 rows x 19 columns. This dataset is not tidy because the columns are not all variables. Route number should be a variable. In order to tidy the dataset, we will need to use `pivot_longer`. 

## How many distinct stations? 

```{r}
distinct_station_df = transit_df %>% 
group_by(station_name) %>% 
distinct(line)
```

There are 465 distinct stations.

## How many stations are ADA compliant? 

```{r}
ADA_comply_df = transit_df %>% 
  filter(ada == TRUE)

station_ADA_df = ADA_comply_df %>% 
group_by(station_name) %>% 
distinct(line)
```

There are 84 ADA compliant stations in the dataset. 

## What is the proportion of stations without vending machines that also have entry access? 
```{r}
no_vending_df = transit_df %>% 
  filter(vending == "NO")

entry_no_vending = no_vending_df %>% 
  filter(entry == TRUE)
  
nrow(entry_no_vending)/nrow(no_vending_df)
```
Around 37.7% of stations without vending machines also have entry access. 

## Reformatting data 

```{r}
line_route_df = transit_df %>% 
   pivot_longer(
   route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A")

distinct_A = line_route_df %>% 
  select(station_name, line, ada) %>% 
  distinct() 

ADA_A_df = distinct_A %>% 
  filter(ada == TRUE)
```
60 distinct stations serve the A train, and of those 17 of them are ADA compliant. 

# Problem 2 

## Mr. Trash Wheel
```{r, message = FALSE, warning = FALSE}
mr_trash_wheel = read_excel('data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx', sheet = "Mr. Trash Wheel", range = "A2:O535") %>% 
  janitor:: clean_names() %>% 
  drop_na() %>% 
  mutate_at(vars(sports_balls), funs(round(., 0))) %>% 
  mutate_at(c('sports_balls'), as.integer) %>% 
  mutate_at(c('dumpster'), as.double)
```

## Professor Trash Wheel 
```{r, message = FALSE}
prof_trash_wheel = read_excel('data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx', sheet = "Professor Trash Wheel", range = "A2:O117") %>% 
  janitor:: clean_names() %>% 
  drop_na() %>% 
  mutate_at(vars(sports_balls), funs(round(., 0))) %>% 
  mutate_at(c('sports_balls'), as.integer)
```

## Joining trash wheel datasets 
```{r}
both_trash_wheels= 
  bind_rows(mr_trash_wheel, prof_trash_wheel)
```

## Dataset description 

The `both_trash_wheels` dataset contains `r nrow(both_trash_wheels)` observations of individual dumpster fills of Mr. Trash Wheel and Professor Trash Wheel. There are `r ncol(both_trash_wheels)` total variables that detail the name of the trash wheel, the full dumpster number, the weight and volume of the full dumpsters, the date the full dumpster was collected, the types of trash collected in the dumpsters, and the homes powered by incineration of the dumpsters. To clean the data, I used the `clean_names` function from the `janitor` package to make all variable names lowercase and snake_case. 

Based on our dataset, the total weight of trash collected by Professor Trash Wheel from Jan 2017 to Jan 2021 was `r sum(prof_trash_wheel$weight_tons)` tons. Additionally, the total number of sports balls collected by Mr. Trash Wheel in 2020 was `r aggregate(sports_balls ~ year, data = mr_trash_wheel, sum) %>% filter(year == 2020) %>% magrittr::extract2("sports_balls")` balls.

# Problem 3 

## Cleaning the pols-month data
```{r, message = FALSE, warning = FALSE}
pols_month = read_csv('data/pols-month.csv') %>% 
  janitor:: clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), convert = T) %>% 
  mutate(month = recode(month, `1` = "jan", `2` = "feb", `3` = "mar", `4` = "apr", `5` = "may", `6` = "jun", `7` = "jul", `8` = "aug", `9` = "sep", `10` = "oct", `11` = "nov", `12` = "dec")) %>% 
  select(year, month, -day, prez_gop, prez_dem, gov_gop, gov_dem, sen_gop, sen_dem, rep_gop, rep_dem) %>% 
  mutate(prez_gop = recode(prez_gop, `1` = "gop", `0` = "dem")) %>% 
  mutate(prez_dem = recode(prez_dem, `1` = "dem", `0` = "gop")) %>% 
pivot_longer(
    prez_gop:prez_dem,
    values_to = "president") %>% 
  select(-name)

```

## Cleaning the snp data 

```{r, warning = FALSE, message = FALSE}
snp = read_csv('data/snp.csv') %>% 
  janitor:: clean_names() %>% 
  separate(date, into = c("month", "day", "year"), convert = T) %>%
  mutate(month = recode(month, `1` = "jan", `2` = "feb", `3` = "mar", `4` = "apr", `5` = "may", `6` = "jun", `7` = "jul", `8` = "aug", `9` = "sep", `10` = "oct", `11` = "nov", `12` = "dec")) %>% 
  mutate(year90s = year + 1900) %>%
  mutate(year00s = year + 2000) %>%
  mutate(year_new = case_when(year > 45 ~ year90s,
                          T ~ year00s)) %>%
  select(year = year_new, month, -day, close)

```

## Cleaning the unemployment data

```{r, warning = FALSE, message = FALSE}
unemployment = read_csv('data/unemployment.csv') %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment rate") 

```

## Joining datasets 

```{r, warning=FALSE, message = FALSE}
pols_snp = full_join (snp, pols_month)

all_three_df = full_join(pols_snp, unemployment)
```

## Merged dataset description 
The `all_three_df` dataset contains `r nrow(all_three_df)` observations of which U.S. political parties were in leadership between 1947-2015 and two important economic variables (unemployment and stock values). There are `r ncol(all_three_df)` total variables that detail presidential, senatorial, house of representatives, and gubernatorial political party affiliations each month between Jan 1947 and Dec 2015, as well as the corresponding unemployment rates and the closing values of the S&P stock index at that time. 

I merged three datasets to create the `all_three_df`. The `pols_month` dataset detailed political affiliations of state and federal government officials each month between 1947-2015. The `snp` dataset detailed the closing values of the S&P stock index each month during the years 1950-2015. The `unemployment` dataset detailed the U.S. unemployment rate each month during the years 1948-2015. Once combined into a single dataset, the resulting dimensions are `r nrow(all_three_df)` rows x `r ncol(all_three_df)` columns.



